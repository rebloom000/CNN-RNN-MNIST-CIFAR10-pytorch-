{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08905d3a-8eec-427c-a22a-8bf9fdfe62c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入包\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets,transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a81c2163-8e73-4e6d-8867-dd3113e07aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#构建transform\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,),(0.5,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67056edc-0412-46ab-83d1-da4eb22146b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/myconda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n"
     ]
    }
   ],
   "source": [
    "#下载，加载数据集\n",
    "\n",
    "trainset = datasets.MNIST('data',train = True, download = True, transform = transform)\n",
    "testset = datasets.MNIST('data',train = False, download = True, transform = transform)\n",
    "\n",
    "device = 'cuda'\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "train_loader = DataLoader(trainset, batch_size = BATCH_SIZE, shuffle = True, num_workers = 16, pin_memory = True)\n",
    "test_loader = DataLoader(testset, batch_size = BATCH_SIZE, shuffle = True, num_workers = 16, pin_memory = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c6cf33e-0321-470b-bcb4-865a5601d6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#构建网络模型\n",
    "\n",
    "class RNN_Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RNN_Net,self).__init__()\n",
    "        #图片 1*28*28\n",
    "        self.hidden_dim = 128\n",
    "        self.layer_dim = 3\n",
    "        #(input_dim, hidden_dim, layer_dim)\n",
    "        self.rnn = nn.RNN(28, 128, 3, batch_first=True, nonlinearity='relu')\n",
    "        self.fc = nn.Linear(128, 10)\n",
    "    def forward(self,x):\n",
    "        # （layer_dim, batch_size, hidden_dim)\n",
    "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_().to(device)\n",
    "        # 分离隐藏状态，避免梯度爆炸\n",
    "        out, hn = self.rnn(x, h0.detach().cuda())\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "#创建模型\n",
    "net = RNN_Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4128c029-2870-4fed-b387-6b1ee06a7ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义优化器和损失函数\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() # 交叉式损失函数\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9) # 优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c04068-1271-4b36-b0d4-cf7dcf692e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :1 , Loss : 0.018\n",
      "Epoch :2 , Loss : 0.018\n",
      "Epoch :3 , Loss : 0.017\n",
      "Epoch :4 , Loss : 0.010\n",
      "Epoch :5 , Loss : 0.005\n",
      "Epoch :6 , Loss : 0.003\n",
      "Epoch :7 , Loss : 0.002\n",
      "Epoch :8 , Loss : 0.002\n",
      "Epoch :9 , Loss : 0.002\n",
      "Epoch :10 , Loss : 0.001\n",
      "Epoch :11 , Loss : 0.001\n"
     ]
    }
   ],
   "source": [
    "#训练模型\n",
    "\n",
    "EPOCH = 15\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    train_loss = 0.0\n",
    "    for i,(datas,labels) in enumerate(train_loader):\n",
    "        #数据处理\n",
    "        datas = datas.view(-1, 28, 28).requires_grad_().to(device)\n",
    "        labels = labels.to(device)\n",
    "        #梯度置零\n",
    "        optimizer.zero_grad()\n",
    "        #训练\n",
    "        outputs = net(datas)\n",
    "        #计算损失\n",
    "        loss = criterion(outputs,labels)\n",
    "        #反向传播\n",
    "        loss.backward()\n",
    "        #参数更新\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    print(\"Epoch :%d , Loss : %.3f\" %(epoch+1, train_loss/len(train_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f97802e-7326-4113-a19c-f9b1d38d39a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for i , (datas, labels) in enumerate(test_loader):\n",
    "        datas = datas.view(-1, 28, 28).to(device)\n",
    "        outputs = net(datas)\n",
    "        _, predicted = torch.max(outputs.data, dim=1) # 第一个是值的张量，第二个是序号的张量\n",
    "        total += labels.size(0)  \n",
    "        correct += (predicted.cuda() == labels.cuda()).sum()\n",
    "    print(\"Accuracy：{:.3f}%\".format(correct / total * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23421432-37b8-4391-8a32-633e5342d81f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myconda",
   "language": "python",
   "name": "myconda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
