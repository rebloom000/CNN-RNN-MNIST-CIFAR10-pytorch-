{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8f046a2-10e1-4b15-921b-67c6240c2f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入包\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data.dataloader import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fedc4c65-b614-4737-bf32-6749d4a2910c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#构建 transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,),(0.5,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2616af53-fec3-48cf-bc39-7d04e5297468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/myconda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n"
     ]
    }
   ],
   "source": [
    "#下载 加载数据集\n",
    "\n",
    "trainset = datasets.CIFAR10(root='./CIFAR10', train=True, download=True, transform=transform)\n",
    "testset = datasets.CIFAR10(root='./CIFAR10', train=False, download=True, transform=transform)\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "device = \"cuda\"\n",
    "\n",
    "train_loader = DataLoader(trainset,batch_size = BATCH_SIZE, shuffle = True, num_workers = 16, pin_memory = True)\n",
    "test_loader = DataLoader(testset,batch_size = BATCH_SIZE, shuffle = True, num_workers = 16, pin_memory = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98426b3d-6ca4-4204-a2eb-e11bb753244e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义网络模型\n",
    "\n",
    "class CNN_Net(nn.Module):\n",
    "    #32*32*3\n",
    "    def __init__(self):\n",
    "        super(CNN_Net,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3,6,5) #28*28*6\n",
    "        self.pool = nn.MaxPool2d(2,2) #14*14*6\n",
    "        self.conv2 = nn.Conv2d(6,20,5) #10*10*20\n",
    "        #5*5*20\n",
    "        self.fc1 = nn.Linear(5*5*20,128)\n",
    "        self.fc2 = nn.Linear(128,64)\n",
    "        self.fc3 = nn.Linear(64,10)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        \n",
    "        x = x.view(-1,5*5*20)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "432e3b60-d41b-4655-8512-5ac93306f540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建模型\n",
    "net = CNN_Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5646123-597a-4425-aa8d-59dd41764531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义优化器和损失函数\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() # 交叉式损失函数\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9) # 优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e639bd40-f814-4178-92c2-b3399551e65a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :1 , Loss : 0.018\n",
      "Epoch :2 , Loss : 0.018\n",
      "Epoch :3 , Loss : 0.017\n",
      "Epoch :4 , Loss : 0.016\n",
      "Epoch :5 , Loss : 0.015\n",
      "Epoch :6 , Loss : 0.014\n",
      "Epoch :7 , Loss : 0.013\n",
      "Epoch :8 , Loss : 0.013\n",
      "Epoch :9 , Loss : 0.012\n",
      "Epoch :10 , Loss : 0.012\n",
      "Epoch :11 , Loss : 0.012\n",
      "Epoch :12 , Loss : 0.011\n",
      "Epoch :13 , Loss : 0.011\n",
      "Epoch :14 , Loss : 0.011\n",
      "Epoch :15 , Loss : 0.011\n",
      "Epoch :16 , Loss : 0.011\n",
      "Epoch :17 , Loss : 0.010\n",
      "Epoch :18 , Loss : 0.010\n",
      "Epoch :19 , Loss : 0.010\n",
      "Epoch :20 , Loss : 0.010\n",
      "Epoch :21 , Loss : 0.010\n",
      "Epoch :22 , Loss : 0.009\n",
      "Epoch :23 , Loss : 0.009\n",
      "Epoch :24 , Loss : 0.009\n",
      "Epoch :25 , Loss : 0.009\n",
      "Epoch :26 , Loss : 0.009\n",
      "Epoch :27 , Loss : 0.009\n",
      "Epoch :28 , Loss : 0.009\n",
      "Epoch :29 , Loss : 0.009\n",
      "Epoch :30 , Loss : 0.008\n",
      "Epoch :31 , Loss : 0.008\n",
      "Epoch :32 , Loss : 0.008\n",
      "Epoch :33 , Loss : 0.008\n",
      "Epoch :34 , Loss : 0.008\n",
      "Epoch :35 , Loss : 0.008\n",
      "Epoch :36 , Loss : 0.008\n",
      "Epoch :37 , Loss : 0.008\n",
      "Epoch :38 , Loss : 0.008\n",
      "Epoch :39 , Loss : 0.008\n",
      "Epoch :40 , Loss : 0.008\n",
      "Epoch :41 , Loss : 0.007\n",
      "Epoch :42 , Loss : 0.007\n",
      "Epoch :43 , Loss : 0.007\n",
      "Epoch :44 , Loss : 0.007\n",
      "Epoch :45 , Loss : 0.007\n",
      "Epoch :46 , Loss : 0.007\n",
      "Epoch :47 , Loss : 0.007\n",
      "Epoch :48 , Loss : 0.007\n",
      "Epoch :49 , Loss : 0.007\n",
      "Epoch :50 , Loss : 0.007\n",
      "Epoch :51 , Loss : 0.007\n",
      "Epoch :52 , Loss : 0.007\n",
      "Epoch :53 , Loss : 0.007\n",
      "Epoch :54 , Loss : 0.006\n",
      "Epoch :55 , Loss : 0.006\n",
      "Epoch :56 , Loss : 0.006\n",
      "Epoch :57 , Loss : 0.006\n",
      "Epoch :58 , Loss : 0.006\n",
      "Epoch :59 , Loss : 0.006\n",
      "Epoch :60 , Loss : 0.006\n",
      "Epoch :61 , Loss : 0.006\n",
      "Epoch :62 , Loss : 0.006\n",
      "Epoch :63 , Loss : 0.006\n",
      "Epoch :64 , Loss : 0.006\n",
      "Epoch :65 , Loss : 0.006\n",
      "Epoch :66 , Loss : 0.006\n",
      "Epoch :67 , Loss : 0.006\n",
      "Epoch :68 , Loss : 0.005\n",
      "Epoch :69 , Loss : 0.005\n",
      "Epoch :70 , Loss : 0.005\n",
      "Epoch :71 , Loss : 0.005\n",
      "Epoch :72 , Loss : 0.005\n",
      "Epoch :73 , Loss : 0.005\n",
      "Epoch :74 , Loss : 0.005\n",
      "Epoch :75 , Loss : 0.005\n",
      "Epoch :76 , Loss : 0.005\n",
      "Epoch :77 , Loss : 0.005\n",
      "Epoch :78 , Loss : 0.005\n",
      "Epoch :79 , Loss : 0.005\n",
      "Epoch :80 , Loss : 0.005\n",
      "Epoch :81 , Loss : 0.005\n",
      "Epoch :82 , Loss : 0.005\n",
      "Epoch :83 , Loss : 0.005\n",
      "Epoch :84 , Loss : 0.005\n",
      "Epoch :85 , Loss : 0.004\n",
      "Epoch :86 , Loss : 0.004\n",
      "Epoch :87 , Loss : 0.004\n",
      "Epoch :88 , Loss : 0.004\n",
      "Epoch :89 , Loss : 0.004\n",
      "Epoch :90 , Loss : 0.004\n",
      "Epoch :91 , Loss : 0.004\n",
      "Epoch :92 , Loss : 0.004\n",
      "Epoch :93 , Loss : 0.004\n",
      "Epoch :94 , Loss : 0.004\n",
      "Epoch :95 , Loss : 0.004\n",
      "Epoch :96 , Loss : 0.004\n",
      "Epoch :97 , Loss : 0.004\n",
      "Epoch :98 , Loss : 0.004\n",
      "Epoch :99 , Loss : 0.004\n",
      "Epoch :100 , Loss : 0.004\n",
      "Epoch :101 , Loss : 0.004\n",
      "Epoch :102 , Loss : 0.003\n",
      "Epoch :103 , Loss : 0.003\n",
      "Epoch :112 , Loss : 0.003\n",
      "Epoch :113 , Loss : 0.003\n",
      "Epoch :114 , Loss : 0.003\n",
      "Epoch :115 , Loss : 0.003\n",
      "Epoch :116 , Loss : 0.003\n",
      "Epoch :117 , Loss : 0.003\n",
      "Epoch :118 , Loss : 0.003\n",
      "Epoch :119 , Loss : 0.003\n",
      "Epoch :120 , Loss : 0.003\n",
      "Epoch :121 , Loss : 0.003\n",
      "Epoch :122 , Loss : 0.003\n",
      "Epoch :123 , Loss : 0.002\n",
      "Epoch :124 , Loss : 0.002\n",
      "Epoch :125 , Loss : 0.002\n",
      "Epoch :126 , Loss : 0.002\n",
      "Epoch :127 , Loss : 0.002\n",
      "Epoch :128 , Loss : 0.002\n",
      "Epoch :129 , Loss : 0.002\n",
      "Epoch :130 , Loss : 0.002\n",
      "Epoch :131 , Loss : 0.002\n",
      "Epoch :132 , Loss : 0.002\n",
      "Epoch :133 , Loss : 0.002\n",
      "Epoch :134 , Loss : 0.002\n",
      "Epoch :135 , Loss : 0.002\n",
      "Epoch :136 , Loss : 0.002\n",
      "Epoch :137 , Loss : 0.002\n",
      "Epoch :138 , Loss : 0.002\n",
      "Epoch :139 , Loss : 0.002\n",
      "Epoch :140 , Loss : 0.002\n",
      "Epoch :141 , Loss : 0.002\n",
      "Epoch :142 , Loss : 0.002\n",
      "Epoch :143 , Loss : 0.002\n",
      "Epoch :144 , Loss : 0.002\n",
      "Epoch :145 , Loss : 0.002\n",
      "Epoch :146 , Loss : 0.002\n",
      "Epoch :147 , Loss : 0.002\n",
      "Epoch :148 , Loss : 0.001\n",
      "Epoch :149 , Loss : 0.001\n",
      "Epoch :150 , Loss : 0.001\n",
      "Epoch :151 , Loss : 0.001\n",
      "Epoch :152 , Loss : 0.001\n",
      "Epoch :153 , Loss : 0.001\n",
      "Epoch :154 , Loss : 0.001\n",
      "Epoch :155 , Loss : 0.001\n",
      "Epoch :156 , Loss : 0.001\n",
      "Epoch :157 , Loss : 0.001\n",
      "Epoch :158 , Loss : 0.001\n",
      "Epoch :159 , Loss : 0.001\n",
      "Epoch :160 , Loss : 0.001\n",
      "Epoch :161 , Loss : 0.001\n",
      "Epoch :162 , Loss : 0.001\n",
      "Epoch :163 , Loss : 0.001\n",
      "Epoch :164 , Loss : 0.001\n",
      "Epoch :165 , Loss : 0.001\n",
      "Epoch :166 , Loss : 0.001\n",
      "Epoch :167 , Loss : 0.001\n",
      "Epoch :168 , Loss : 0.001\n",
      "Epoch :169 , Loss : 0.001\n",
      "Epoch :170 , Loss : 0.001\n",
      "Epoch :171 , Loss : 0.001\n",
      "Epoch :172 , Loss : 0.001\n",
      "Epoch :173 , Loss : 0.001\n",
      "Epoch :174 , Loss : 0.001\n",
      "Epoch :175 , Loss : 0.001\n",
      "Epoch :176 , Loss : 0.001\n",
      "Epoch :177 , Loss : 0.001\n",
      "Epoch :178 , Loss : 0.001\n",
      "Epoch :179 , Loss : 0.001\n",
      "Epoch :180 , Loss : 0.001\n",
      "Epoch :181 , Loss : 0.001\n",
      "Epoch :182 , Loss : 0.001\n",
      "Epoch :183 , Loss : 0.001\n",
      "Epoch :184 , Loss : 0.001\n",
      "Epoch :185 , Loss : 0.001\n",
      "Epoch :186 , Loss : 0.001\n",
      "Epoch :187 , Loss : 0.001\n",
      "Epoch :188 , Loss : 0.001\n",
      "Epoch :189 , Loss : 0.001\n",
      "Epoch :190 , Loss : 0.001\n",
      "Epoch :191 , Loss : 0.001\n",
      "Epoch :192 , Loss : 0.001\n",
      "Epoch :193 , Loss : 0.000\n",
      "Epoch :194 , Loss : 0.000\n",
      "Epoch :195 , Loss : 0.000\n",
      "Epoch :196 , Loss : 0.000\n",
      "Epoch :197 , Loss : 0.000\n",
      "Epoch :198 , Loss : 0.000\n",
      "Epoch :199 , Loss : 0.000\n",
      "Epoch :200 , Loss : 0.000\n"
     ]
    }
   ],
   "source": [
    "#训练\n",
    "\n",
    "EPOCHS = 200\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    train_loss = 0.0\n",
    "    \n",
    "    for i, (datas, labels) in enumerate(train_loader):\n",
    "        datas, labels = datas.to('cuda'), labels.to('cuda')\n",
    "        # 梯度置零\n",
    "        optimizer.zero_grad()\n",
    "        # 训练\n",
    "        outputs = net(datas)\n",
    "        # 计算损失\n",
    "        loss = criterion(outputs, labels)\n",
    "        # 反向传播\n",
    "        loss.backward()\n",
    "        # 参数更新\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "    print(\"Epoch :%d , Loss : %.3f\"%(epoch+1, train_loss/len(train_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8a78e98-68fd-4b6d-b75a-411c3fa24871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型\n",
    "PATH = './cnn_cifar_net.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d06665-7d1a-41e0-b959-4944bd4e1619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载模型\n",
    "\n",
    "model = CNN_Net()\n",
    "model.load_state_dict(torch.load(PATH)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f333b4-01a5-4839-962f-f2f12e99442d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for i , (datas, labels) in enumerate(test_loader):\n",
    "        outputs = model(datas)\n",
    "        _, predicted = torch.max(outputs.data, dim=1) # 第一个是值的张量，第二个是序号的张量\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum()\n",
    "    print(\"Total Accuracy：{:.3f}%\".format(correct / total * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c401e0b-17a9-4377-b5ea-ac5b5d727c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 显示每一类预测的概率\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "class_correct = list(0. for i in range(10))\n",
    "total = list(0. for i in range(10))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for (images, labels) in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, dim=1) # 获取到每一行最大值的索引\n",
    "        c = (predicted == labels).squeeze() # squeeze() 去掉0维【默认】， unsqueeze() 增加一维\n",
    "        if labels.shape[0] == 128:\n",
    "            for i in range(BATCH_SIZE):\n",
    "                label = labels[i] # 获取每一个label\n",
    "                class_correct[label] += c[i].item() # 累计为True的个数, 注意：1 + True = 2, 1 + False = 1\n",
    "                total[label] += 1 # 该类总的个数\n",
    "            \n",
    "for i in range(10):\n",
    "    print(\"Accuracy ： %5s : %2d %%\" % (classes[i], 100 * class_correct[i] / total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac391589-180d-4271-8e95-51939569c4f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myconda",
   "language": "python",
   "name": "myconda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
